ASL Recognition using ML and DL

Introduction to ASL

American Sign Language (ASL) is a visual language used primarily by the Deaf and Hard of Hearing community in the United States and parts of Canada. It uses hand gestures, facial expressions, and body movements to communicate. This project focuses on recognizing ASL letters (A-Z) and digits (0-9).


Objective

Our solution aims to build a system that accurately recognizes ASL letters and digits using machine learning (ML) and deep learning (DL) techniques. We compare traditional ML models with advanced DL architectures to find the best approach for real-time applications.

A short demo of our project

https://youtu.be/L2WTQ3KFwNE

Workflow Diagram

![workflow](https://github.com/user-attachments/assets/8e38f72c-9024-431f-8b57-7f9585220a8e)

Caption: Overview of the project pipeline, from data collection to model deployment.


Models Used

Machine Learning models:  Support Vector Machine (SVM)  XGBoost  Multi-Layer Perceptron (MLP)

Deep Learning models:  ResNet50  VGG16  EfficientNetB0


Output Images

![SVM](https://github.com/user-attachments/assets/3d054734-bc74-40f2-9f05-c90ed66f1651)

![RESNET](https://github.com/user-attachments/assets/1257c963-bc05-4d5c-938a-eb1cc0e5b443)

Caption: Real time ASL recognition images for SVM and ResNet50 models.


Dependencies

Python 3.8+  
PyTorch  
OpenCV  
MediaPipe  
Scikit-learn
